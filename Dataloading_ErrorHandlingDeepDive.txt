1. Create a Database - sfdb
create or replace database snowflake_exercise;
2. Create a Schema - sf_schema
create schema sf_schema;

3. Create a file Format
create or replace file format my_csv_format type=csv skip_header=1 ;

describe file format my_csv_format
4. Create Table Emp
use snowflake_exercise;
use schema sf_schema;
create or replace table emp(  
	empno    number,  
	ename    varchar(100),  
	job      varchar(25),  
	mgr      number,  
	hiredate varchar(100),  
	sal      number,  
	comm     number,  
	deptno   number  
	)
   STAGE_FILE_FORMAT = ( FORMAT_NAME = 'my_csv_format');

5. To Get the Script of Created Object
   select get_ddl(<object type>, '<Object Name>' );
   Select get_ddl('database','snowflake_exercise');
   Select get_ddl('schema','sf_schema');
   Select get_ddl('table','emp');
   
6. Create Stage 
/*   Create Stage my_internal_stage; -- with out file format
   Create Stage my_internal_stage file_format=my_csv_format; -- Internal Named stage 
   
   LIST @my_internal_stage;*/
  --external named stage
  /*create or replace stage my_external_stg
  storage_integration = storage_s3_integration
  url = 's3://skillsrawbucket/DW/';*/

CREATE STAGE my_external_stg URL = 's3://skillscaleraw/DW/' 
CREDENTIALS = (AWS_KEY_ID = 'AKIAU54YTHYE3ECTUVDL' AWS_SECRET_KEY = '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');

LIST @my_external_stg 
  --file_format = my_csv_format;
  
 List @my_external_stg/employee/;
 ALTER STAGE my_external_stg set file_format=my_csv_format;

 CST
7. Query From Stage
    External Named Stage
    --------------------
    LIST @my_external_stg/employee
    
    Select $1,$2,$3,$4,$5,$6,$7,$8  from @my_external_stg/employee/emp.csv (file_format => 'my_csv_format')
   
    Select $1 as empid,$3 as job from @my_external_stg/employee/ (file_format => 'my_csv_format') limit 5;
    Select $1,$6,$3 as job,$8 from @my_external_stg/employee/emp.csv (file_format => 'my_csv_format') limit 5;

8.loading specific set of files and data in differnt order
  copy into emp (EMPNO,ENAME,JOB,MGR,SAL) from (Select $1,$2,$3,$4,$6 from @my_external_stg/employee/emp.csv) 
	 file_format = 'my_csv_format' FORCE=TRUE;	 
-- OTHER COPY OPTIONS
 copy into emp from (Select $1,$2,$3,$4,$5,$6,$7,$8 from @my_external_stg/employee/) 
 FILES = ('emp.csv','emp_load1.csv')  file_format = 'my_csv_format' FORCE=TRUE;	 
 
   LIST @my_external_stg/employee/  pattern='.*emp_load.*[0-9].*.csv'
  -- load files with specific naming pattern in file names 
 copy into emp from (Select $1,$2,$3,$4,$5,$6,$7,$8 from @my_external_stg/employee/) 
  pattern='.*emp_load.*[0-9].*.csv' file_format = 'my_csv_format' FORCE=TRUE;
  
   --pattern='.*emp_load.*[0-9].*.csv'

list @my_external_stg pattern='.*emp_load.*[0-9].*.csv'

copy into emp from (Select $1, cast($4 as number),$2,$7,$8 from @my_external_stg/employee/) 
  file_format = 'my_csv_format'FORCE=TRUE;
  
  Select $1, cast($4 as number),$2,$7,$8 from @my_external_stg/employee/emp.csv (file_format = 'my_csv_format');
  Select $1,$6,$8 from @my_external_stg/employee/emp.csv (file_format => 'my_csv_format') limit 5;
The COPY command supports:

Column reordering, 
column omission
casts using a SELECT statement.

TRUNCATE COLUMN

The ENFORCE_LENGTH | TRUNCATECOLUMNS option, which can truncate text strings that exceed the target column length*/
  
copy into emp() from (Select $1,$2,$3,$4,$5,$6,$7,$8 from @my_external_stg/employee/emp) 
  file_format = 'my_csv_format'FORCE=TRUE TRUNCATECOLUMNS = TRUE;


select *
from table(information_schema.copy_history(table_name=>'emp', start_time=> dateadd(hours, -24, current_timestamp())));


10. Error Handling in COPY Command


/*ON_ERROR = { CONTINUE | SKIP_FILE | SKIP_FILE_<num> | SKIP_FILE_<num>% | ABORT_STATEMENT } --
SKIP_FILE_num (e.g. SKIP_FILE_5)
Skip a file when the number of error rows found in the file is equal to or exceeds the specified number.

SKIP_FILE_num% (e.g. SKIP_FILE_0.01%)
Skip a file when the percentage of error rows found in the file exceeds the specified percentage.
copy into emp from @EXTERNAL_STG/emp_error.csv file_format = my_csv_format*/

-- once upload error file into your datalake path in cloud storage
copy into emp from @my_external_stg/employee/ file_format = my_csv_format;
copy into emp from @my_external_stg/employee/ file_format = my_csv_format ON_ERROR=ABORT_STATEMENT FORCE=TRUE;

copy into emp from @my_external_stg/employee/ file_format = my_csv_format ON_ERROR=SKIP_FILE;

copy into emp from @my_external_stg/employee/emp_error_file.csv file_format = my_csv_format ON_ERROR=CONTINUE;

copy into emp from @my_external_stg/employee/ file_format = my_csv_format ON_ERROR=SKIP_FILE_2 FORCE=TRUE;

copy into emp from @my_external_stg/employee/ file_format = my_csv_format ON_ERROR=CONTINUE FORCE=TRUE;

copy into emp from @my_external_stg/employee/ file_format = my_csv_format ON_ERROR=SKIP_FILE_3 FORCE=TRUE;

copy into emp from @my_external_stg/employee/emp_error_file.csv file_format = my_csv_format ON_ERROR=SKIP_FILE_3 FORCE=TRUE;

copy into emp from @my_external_stg/employee/ file_format = my_csv_format ON_ERROR='SKIP_FILE_0.01%';

copy into emp from @my_external_stg/employee/ file_format = my_csv_format ON_ERROR=SKIP_FILE_1 FORCE=TRUE;

copy into emp from @my_external_stg/ file_format = my_csv_format on_error=CONTINUE force=true;

-- for capturing rejected rows we will use validate table function for which we will have to pass table name and queryid as input parameters

select * from table(validate(emp, job_id=> '01a6ff9d-3200-8a74-0001-b3be0003c0f6'));
