1. Create a Database - sfdb
create or replace database snowflake_exercise;
2. Create a Schema - sf_schema
create schema sf_schema;

3. Create a file Format
create or replace file format my_csv_format type=csv skip_header=1 ;

describe file format my_csv_format
4. Create Table Emp
use snowflake_exercise;
use schema sf_schema;
create or replace table emp(  
	empno    number,  
	ename    varchar(100),  
	job      varchar(25),  
	mgr      number,  
	hiredate varchar(100),  
	sal      number,  
	comm     number,  
	deptno   number  
	)
   STAGE_FILE_FORMAT = ( FORMAT_NAME = 'my_csv_format');

5. To Get the Script of Created Object
   select get_ddl(<object type>, '<Object Name>' );
   Select get_ddl('database','snowflake_exercise');
   Select get_ddl('schema','sf_schema');
   Select get_ddl('table','emp');
   
6. Create Stage 
/*   Create Stage my_internal_stage; -- with out file format
   Create Stage my_internal_stage file_format=my_csv_format; -- Internal Named stage 
   
   LIST @my_internal_stage;*/
  --external named stage
  /*create or replace stage my_external_stg
  storage_integration = storage_s3_integration
  url = 's3://skillsrawbucket/DW/';*/

CREATE STAGE my_external_stg URL = 's3://skillscaleraw/DW/' 
CREDENTIALS = (AWS_KEY_ID = 'AKIAU54YTHYE3ECTUVDL' AWS_SECRET_KEY = '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');

LIST @my_external_stg 
  --file_format = my_csv_format;
  
 List @my_external_stg/employee/;
 ALTER STAGE my_external_stg set file_format=my_csv_format;

 CST
7. Query From Stage
    External Named Stage
    --------------------
    LIST @my_external_stg/employee
    
    Select $1,$2,$3,$4,$5,$6,$7,$8  from @my_external_stg/employee/emp.csv (file_format => 'my_csv_format')
   
    Select $1 as empid,$3 as job from @my_external_stg/employee/ (file_format => 'my_csv_format') limit 5;
    Select $1,$6,$3 as job,$8 from @my_external_stg/employee/emp.csv (file_format => 'my_csv_format') limit 5;

8.loading specific set of files and data in differnt order
  copy into emp (EMPNO,ENAME,JOB,MGR,SAL) from (Select $1,$2,$3,$4,$6 from @my_external_stg/employee/emp.csv) 
	 file_format = 'my_csv_format' FORCE=TRUE;	 
-- OTHER COPY OPTIONS
 copy into emp from (Select $1,$2,$3,$4,$5,$6,$7,$8 from @my_external_stg/employee/) 
 FILES = ('emp.csv','emp_load1.csv')  file_format = 'my_csv_format' FORCE=TRUE;	 
 
   LIST @my_external_stg/employee/  pattern='.*emp_load.*[0-9].*.csv'
  -- load files with specific naming pattern in file names 
 copy into emp from (Select $1,$2,$3,$4,$5,$6,$7,$8 from @my_external_stg/employee/) 
  pattern='.*emp_load.*[0-9].*.csv' file_format = 'my_csv_format' FORCE=TRUE;
  
   --pattern='.*emp_load.*[0-9].*.csv'

list @my_external_stg pattern='.*emp_load.*[0-9].*.csv'

copy into emp from (Select $1, cast($4 as number),$2,$7,$8 from @my_external_stg/employee/) 
  file_format = 'my_csv_format'FORCE=TRUE;
  
  Select $1, cast($4 as number),$2,$7,$8 from @my_external_stg/employee/emp.csv (file_format = 'my_csv_format');
  Select $1,$6,$8 from @my_external_stg/employee/emp.csv (file_format => 'my_csv_format') limit 5;
The COPY command supports:

Column reordering, 
column omission
casts using a SELECT statement.

TRUNCATE COLUMN

The ENFORCE_LENGTH | TRUNCATECOLUMNS option, which can truncate text strings that exceed the target column length*/
  
copy into emp() from (Select $1,$2,$3,$4,$5,$6,$7,$8 from @my_external_stg/employee/emp) 
  file_format = 'my_csv_format'FORCE=TRUE TRUNCATECOLUMNS = TRUE;


select *
from table(information_schema.copy_history(table_name=>'emp', start_time=> dateadd(hours, -24, current_timestamp())));


9. Error Handling in COPY Command


/*ON_ERROR = { CONTINUE | SKIP_FILE | SKIP_FILE_<num> | SKIP_FILE_<num>% | ABORT_STATEMENT } --
SKIP_FILE_num (e.g. SKIP_FILE_5)
Skip a file when the number of error rows found in the file is equal to or exceeds the specified number.

SKIP_FILE_num% (e.g. SKIP_FILE_0.01%)
Skip a file when the percentage of error rows found in the file exceeds the specified percentage.
copy into emp from @EXTERNAL_STG/emp_error.csv file_format = my_csv_format*/

-- once upload error file into your datalake path in cloud storage
copy into emp from @my_external_stg/employee/ file_format = my_csv_format;
copy into emp from @my_external_stg/employee/ file_format = my_csv_format ON_ERROR=ABORT_STATEMENT FORCE=TRUE;

copy into emp from @my_external_stg/employee/ file_format = my_csv_format ON_ERROR=SKIP_FILE;

copy into emp from @my_external_stg/employee/emp_error_file.csv file_format = my_csv_format ON_ERROR=CONTINUE;

copy into emp from @my_external_stg/employee/ file_format = my_csv_format ON_ERROR=SKIP_FILE_2 FORCE=TRUE;

copy into emp from @my_external_stg/employee/ file_format = my_csv_format ON_ERROR=CONTINUE FORCE=TRUE;

copy into emp from @my_external_stg/employee/ file_format = my_csv_format ON_ERROR=SKIP_FILE_3 FORCE=TRUE;

copy into emp from @my_external_stg/employee/emp_error_file.csv file_format = my_csv_format ON_ERROR=SKIP_FILE_3 FORCE=TRUE;

copy into emp from @my_external_stg/employee/ file_format = my_csv_format ON_ERROR='SKIP_FILE_0.01%';

copy into emp from @my_external_stg/employee/ file_format = my_csv_format ON_ERROR=SKIP_FILE_1 FORCE=TRUE;

copy into emp from @my_external_stg/ file_format = my_csv_format on_error=CONTINUE force=true;

-- for capturing rejected rows we will use validate table function for which we will have to pass table name and queryid as input parameters

select * from table(validate(emp, job_id=> '01a6ff9d-3200-8a74-0001-b3be0003c0f6'));

10. Validate Data in the File -- No loading -- No Data loding into the table
  copy command with validation_mode -- Return_n_rows, return_errors, return_all_errors;
truncate table emp
select * from emp
copy into emp from @my_external_stg/employee/emp.csv file_format = my_csv_format validation_mode=return_errors FORCE=TRUE;

copy into emp from @my_external_stg/employee/ file_format = my_csv_format validation_mode=return_all_errors ;


copy into emp from @my_external_stg/employee/emp_error_file.csv file_format = my_csv_format validation_mode=return_5_rows ;

copy into emp from @my_external_stg/employee/emp.csv file_format = my_csv_format validation_mode=return_10_rows ;
  
copy into emp from @my_external_stg/employee/emp_error_file.csv file_format = my_csv_format validation_mode=return_5_rows;
    
11. How do we store the erroneous data into a Table with Validation_mode
    --Using Result Scan Table Function we can log the errors
	-- After Executing the Copy Command get the last Query ID and pass it to Result Scan Function
    --01a1708d-0000-2b7e-0000-00007a0d131d
select last_query_id();    
select last_query_id(-1);  --01a6ff87-3200-8a62-0001-b3be00037256
    
    --select last_query_id();
    Select * from table(result_scan('01a6ff83-3200-8a75-0001-b3be0003a046'));
	--Create a Table out of Errored Rows
	select last_query_id();
    set quid=last_query_id(-1);
    Select $quid from dual;
	Select $quid;
    copy into emp from @my_external_stg/employee/ file_format = my_csv_format validation_mode=return_all_errors;
    
    Create or replace table emp_err_log as select * from table(result_scan(last_query_id()));
    select * from emp_err_log
Validate Data in the File -- No loading -- No Data loding into the table
  copy command with validation_mode -- Return_n_rows, return_errors, return_all_errors;    
12. Load Data in to the File even if there are errors in data 
    --  Data loding into the table using on_error = Continue
    --copy into table with on_error=continue. If there are errors data gets loaded partially
    
    -- 1000000
   -- 10
   
	 
   copy into emp from @my_external_stg/employee/emp_error_file.csv file_format = my_csv_format on_error=continue force=true;

  set Q_ID=  LAST_QUERY_ID(-2)  --01adad62-3200-cb1d-0004-f0060006c02e

  select $Q_ID
     
    select * from table(validate(emp, job_id=>'_last'));
      
    create or replace table emp_err_log as select * from table(validate(emp, job_id=>'_last'));
     
     select * from emp_err_log;
     
     set quid=last_query_id(-1);
     select $quid
     
     insert into emp_err_log
     select * from table(validate(emp, job_id=>$quid));
     
     select * from table(validate(emp, job_id=> '01a6ff9d-3200-8a74-0001-b3be0003c0f6'));
     select * from table(validate(emp, job_id=> $quid));
     
  
	How do we store the erroneous data into table err_log
    --Using validate Function we can log the errors
     create or replace table emp_err_log as 
     select * from table(validate(<table_name>, job_id=><query_id_of_the_copy_command>));
	 
     create or replace table emp_err_log as 
     select * from table(validate(emp, job_id=>'01ad9cb0-3200-c9e4-0004-f006000540e2'));  -- _last will provide query id of last statement that got executed in this session
     
     select * from emp_err_log;
12. get load status of files that got loaded through COPY command     
--Retrieve details about all loading activity in the last hour:

-- information_schema.copy_history table function stores copy history for 14 days including snowpipe copy commands
select *
from table(information_schema.copy_history(table_name=>'emp', start_time=> dateadd(hours, -76, current_timestamp())));

-- information_schema.load_history view stores copy history for 14 days and view does not return the history of data loaded using Snowpipe
select * from information_schema.load_history order by last_load_time desc
  limit 10;

select * from information_schema.load_history order by last_load_time desc
  limit 10;
  
-- snowflake.account_usage.copy_history will have  -- 365 days
select * from snowflake.account_usage.copy_history
  order by last_load_time desc
  limit 10;
  select * from snowflake.account_usage.QUERY_HISTORY order by start_time desc;
 ---- Result scan function
    
    select last_query_id(-2);  -- 2nd most recent query_id
Retrieve all values from your second most recent query in the current session:
select * from table(result_scan(last_query_id(-2)));
Retrieve all values from your first query in the current session:
Select last_query_id(5);     -- get first query of current session

select * from emp
select * from table(result_scan('01adad91-3200-cb07-0004-f0060006909a'))
-- check default role of a user
desc user SKILLSCALER;  

select "property", "value" from table(result_scan(last_query_id())) 
where "property" = 'DEFAULT_ROLE';

--Extract empty tables that are older than 21 days from show command


show tables
select "kind","name" from table(result_scan(last_query_id())) t  where "kind"='TABLE'

show tables
-- Show the tables that are more than 21 days old and that are empty
-- (i.e. tables that I might have forgotten about).

select "database_name", "schema_name", "name" as "table_name", "rows", "created_on"
    from table(result_scan(last_query_id(-3)))
    where "rows" = 6
    and "created_on" < dateadd(day, -21, current_timestamp())
    order by "created_on";